python -m inst_follow.eval.tydiqa.run_eval \
    --data_dir data/eval/tydiqa/ \
    --n_shot 1 \
    --max_num_examples_per_lang 100 \
    --max_context_length 512 \
    --save_dir results/tydiqa/llama-7B-no-context-1shot \
    --model llama_alpaca_finetune/poly_mu_alpaca/loss=0.5422.ckpt \
    --example_to_ids_path inst_follow/cluster_infos/atlas_by_instr_text-embedding-ada-002_ldalayer1.pkl \
    --tokenizer yahma/llama-7b-hf \
    --eval_batch_size 80 \
    --no_context \
    --use_chat_format