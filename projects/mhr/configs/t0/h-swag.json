{
    "dataset": "t0",
    "finetune_task_name": "h-swag",
    "train_batch_size": 4,
    "predict_batch_size": 16,
    "gradient_accumulation_steps": 2,
    "length_norm": 1,
    "mc_loss": 1,
    "unlikely_loss": 1
}