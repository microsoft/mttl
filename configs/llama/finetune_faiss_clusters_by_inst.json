{
    "dataset": "alpaca",
    "optimizer": "adamw",
    "learning_rate": 3e-4, 
    "exp_name": "alpaca_lora_faiss_100_clusters_instr",
    "train_dir": "$AP_DATA_DIR",
    "precision": "bf16",
    "train_batch_size": 128,
    "model": "yahma/llama-7b-hf",
    "lora_rank": 4,  
    "num_train_epochs": 4,
    "n_skills": 100,
    "max_input_length": 256,  
    "poly_selector":"cluster_soft",  
    "poly_selector_use_distances": 1,
    "example_to_ids_path": "/home/v-oostapenko/dev/mttl/compositional_adapters/data/cluster_infos/faiss_by_instr.pkl",
    "model_modifier": "poly_lora",  
    "lora_modules": ".*attn",  
    "lora_layers": "v_proj|q_proj|k_proj|o_proj",
    "trainable_param_names": ".*lora_[ab].*|.*module_logits.*",
    "output_dir":"/home/v-oostapenko/logs/llama_alpaca/lora_faiss_100_cluster_instr"
}